from airflow.decorators import dag, task
from airflow.models.param import Param
from airflow.operators.python import get_current_context
from airflow.utils.dates import days_ago
from kubernetes.client import models as k8s


class Constants:
    DAG_NAME = "kg_data_pipeline"
    DAG_SCHEDULE = "0 15 * * *"  # 3 PM UTC or 8 AM PST - recurring schedule daily
    DAG_OWNER = "airflow"
    ORG = "ybor"  # {{ org-name }} - best generated by an archetype macro
    VENTURE = "playground"  # {{ venture-name }} - best generated by an archetype macro
    ENV = "dev"  # usually dev, stg or prod

    # CI/CD Configurations
    DOCKER_IMAGE_PREFIX = f"p6m.jfrog.io/{ORG}-{VENTURE}-docker/applications"
    KG_DRIVER_DOCKER_IMAGE = f"{DOCKER_IMAGE_PREFIX}/ybor-graph-query-adapter-server:main"


    PULL_SECRET = "dockerconfig"  # "regcred"
    KG_SECRETS = "kg-secrets"
    KG_CONFIGMAP = "kg-cmap"

    # other constants
    ISTIO_ANNOTATION = "sidecar.istio.io/inject"
    DO_NOT_EVICT = "karpenter.sh/do-not-evict"
    DO_NOT_CONSOLIDATE = "karpenter.sh/do-not-consolidate"
    DO_NOT_DISRUPT = "karpenter.sh/do-not-disrupt"


dag_parameters = {
    "mode": Param(
        "development",
        type="string",
        title="Development or Production run?",
        description="(mandatory) Development or Production ?",
    ),
    "output_database": Param(
        "playground",
        type="string",
        title="Destination database where the output should be register to",
        description="(mandatory) Database name for current Run",
    )
}

kg_configmap = k8s.V1EnvFromSource(
    config_map_ref=k8s.V1ConfigMapEnvSource(name=Constants.KG_CONFIGMAP)
)
kg_secrets = k8s.V1EnvFromSource(
        secret_ref=k8s.V1SecretEnvSource(name=Constants.KG_SECRETS)
    )

@task
def init_task(args) -> dict:
    from datetime import datetime

    print(f"init_task args = {args}")
    dag_run = get_current_context()["dag_run"]
    print(f"init_task dag_run = {dag_run}")

    return args

@task.kubernetes(
    task_id="kg_ingestion",
    name="kg_ingestion_task",
    namespace="airflow",
    image=Constants.KG_DRIVER_DOCKER_IMAGE,
    in_cluster=True,
    get_logs=True,
    # service_account_name=Constants.TRANSFORMS_SERVICE_ACCOUNT,
    do_xcom_push=True,
    image_pull_secrets=[k8s.V1LocalObjectReference(Constants.PULL_SECRET)],
    is_delete_operator_pod=False,
    env_from=[kg_secrets, kg_configmap],
    # labels={"app": "transformations", "app_type": "driver"},
    # annotations={
    #     Constants.ISTIO_ANNOTATION: "false", Constants.DO_NOT_EVICT: "true",
    #     Constants.DO_NOT_CONSOLIDATE: "true", Constants.DO_NOT_DISRUPT: "true"},
    container_resources=k8s.V1ResourceRequirements(
        requests={"memory": "1Gi", "cpu": "2.0", "ephemeral-storage": "1Gi"},
        limits={"memory": "2Gi", "cpu": "2.0", "ephemeral-storage": "3Gi"},
    ),
    # priority_class_name="workflow",
)
def kg_ingestion_task(args: dict) -> dict:
    import logging

    # use {{ org_name }}_{{ venture_name }} archetype macro
    from ybor_graph_query_adapter.main import run

    logger = logging.getLogger(__name__)
    logging.basicConfig(level=logging.INFO)

    logger.info(f"input = {args}")
    rc = run()
    logger.info(f"output = {rc}")
    path = rc.get("s3_path", None)
    if path:
        args["input_file"] = path
    return args



@dag(
    dag_id=Constants.DAG_NAME,
    default_args={
        "owner": Constants.DAG_OWNER,
        "depends_on_past": False,
    },
    params=dag_parameters,
    start_date=days_ago(1),
    schedule_interval=None, # Constants.DAG_SCHEDULE,
    max_active_runs=1,
)
def workflow():

    # kg_secrets = k8s.V1EnvFromSource(
    #     secret_ref=k8s.V1SecretEnvSource(name=Constants.kg_secrets)
    # )

    # Note : This task will go away shortly
    @task
    def echo_task(args: dict) -> dict:
        print(args)
        return args

    # pipe output of each stage as input to the next stage

    scheduler_info = {
        "scheduler_from_date": "{{ prev_data_interval_end_success }}",
        "scheduler_to_date": "{{ data_interval_end }}",
    }

    input_args = init_task(scheduler_info)
    kg_output = kg_ingestion_task(input_args)
    echo_task(kg_output)


workflow()
